{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from alphaPhosHelperFunctions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "import plotly.figure_factory as ff\n",
    "from PeptideCollapse import *\n",
    "import analytics_core_V04 as ac\n",
    "import kinase_library as kl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kinase_prediction (dataset, kinase_df, group1, group2, kinase_class = \"ser_thr\"):\n",
    "    import kinase_library as kl\n",
    "    ###### Preparing kinase format\n",
    "    kinase_df_copy = kinase_df.copy()\n",
    "    def replace_between_asterics(match):\n",
    "        return match.group(1).upper()\n",
    "    tmp1 = []\n",
    "    for el in kinase_df_copy['kinase_sequence'].tolist():\n",
    "        tmp = re.sub(r'\\*([^*]+)\\*', replace_between_asterics, el)\n",
    "        tmp1.append(tmp.replace('_', '').upper())\n",
    "        \n",
    "    kinase_df_copy['kinase_sequence'] = tmp1\n",
    "    kinase_df_copy['PTM_Collapse_key'] = kinase_df_copy['PTM_Collapse_key'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[0]) + '_' + 'p' + kinase_df_copy['PTM_Collapse_key'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[1])\n",
    "    ###### \n",
    "    dataset_copy = dataset.copy()\n",
    "    dataset_copy = dataset_copy[(dataset_copy['group'] == group1) | (dataset_copy['group'] == group2)]\n",
    "    #dataset_copy = ac.filt_per_percentage(dataset_copy, 0.7)\n",
    "    #dataset_copy = ac.imputation_normal_distribution(dataset_copy).reset_index()\n",
    "    ttest_result = ac.run_ttest(dataset_copy, group1, group2)\n",
    "    ttest_result['identifier'] = ttest_result['identifier'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[0]) + '_' + 'p' + ttest_result['identifier'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[1])\n",
    "    ttest_result = ttest_result.sort_values('identifier')\n",
    "    ttest_result.columns = ['PTM_Collapse_key', 'T-statistics', 'pvalue', 'mean_group1', 'mean_group2',\n",
    "        'std(group1)', 'std(group2)', 'log2FC', 'test', 'correction', 'padj',\n",
    "       'rejected', 'group1', 'group2', 'FC', '-log10 pvalue', 'Method']\n",
    "    kinases = pd.DataFrame()\n",
    "    kinases = kinase_df_copy.merge(ttest_result, on = 'PTM_Collapse_key')\n",
    "    kinases = kinases[['PTM_Collapse_key','kinase_sequence', 'log2FC', 'T-statistics', 'padj']]\n",
    "    kinases.columns = ['Phosphosites', 'Sequence', 'logFC', 't', 'adj.P.Val']\n",
    "    test = kl.DiffPhosData(kinases, lfc_col='logFC', seq_col='Sequence', pval_col='adj.P.Val', pval_thresh=0.1)\n",
    "    kin_type = kinase_class\n",
    "    method = 'percentile_rank'\n",
    "    thresh = 15\n",
    "    test1 = test.kinase_enrichment(kin_type=kin_type, kl_method=method, kl_thresh=thresh)\n",
    "    fin_df = test1.combined_enrichment_results\n",
    "    return fin_df, test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhosphoAnalysis:\n",
    "    def __init__(self):\n",
    "        self.processor = PeptideCollapse()\n",
    "        self.condition_df = None\n",
    "        self.collapsed_data = None\n",
    "        self.formatted_data = None\n",
    "        \n",
    "    \n",
    "    def peptideCollapse(self, data, **kwargs):\n",
    "        \n",
    "        self.collapsed_data = self.processor.process_complete_pipeline(\n",
    "            data=data, \n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        return self.collapsed_data \n",
    "        \n",
    "    def assign_condition_setup(self, condition_df=None):\n",
    "        \n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        \n",
    "        df_copy = self.collapsed_data.copy()\n",
    "        \n",
    "        if condition_df is None:\n",
    "            condition_df = self.processor.get_precursor_condition_dataset() \n",
    "            \n",
    "            \n",
    "            print(\"Assign conditions to each sample\")\n",
    "        \n",
    "            for i, sample in enumerate(condition_df['Sample']):\n",
    "                condition = input(f\"Enter condition for '{sample}': \")\n",
    "                condition_df.loc[i, 'Condition'] = condition\n",
    "            \n",
    "            quant_cols = condition_df['Sample'].unique().tolist()\n",
    "            meta_cols = [col for col in df_copy.columns if col not in quant_cols]\n",
    "            quant_df, meta_df = df_copy[quant_cols].T, df_copy[meta_cols].T\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            quant_cols = condition_df['Sample'].unique().tolist()\n",
    "            meta_cols = [col for col in df_copy.columns if col not in quant_cols]\n",
    "            quant_df, meta_df = df_copy[quant_cols].T, df_copy[meta_cols].T\n",
    "        \n",
    "        tmp_dict = dict(zip(condition_df['Sample'], condition_df['Condition']))\n",
    "        quant_df.columns = meta_df.loc[\"PTM_Collapse_key\"]\n",
    "        quant_df['group'] = quant_df.index.map(tmp_dict)\n",
    "        quant_df['sample'] = (quant_df['group'] + '_' + (quant_df.groupby('group').cumcount() + 1).astype(str))\n",
    "        quant_df['subject'] = quant_df['sample']\n",
    "        \n",
    "        self.formatted_data = quant_df\n",
    "        self.condition_df = condition_df\n",
    "        \n",
    "        return quant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_phospho_median(phospho_df, protein_df, return_non_matched=False):\n",
    "    \"\"\"\n",
    "    Normalize phosphoproteomics data using condition-level protein-specific normalization.\n",
    "\n",
    "    This function normalizes each phosphosite by subtracting the median abundance of its\n",
    "    corresponding parent protein within each condition. Samples with the same name are\n",
    "    treated as replicates of the same condition. This approach preserves condition-specific\n",
    "    protein expression changes while providing phosphorylation stoichiometry information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phospho_df : pandas.DataFrame\n",
    "        Phosphoproteomics dataframe with samples as index and phosphosites as columns.\n",
    "        Column names should contain protein identifiers (e.g., 'P12345~PROTEIN_S123').\n",
    "        Values should be log-transformed intensities. Duplicate sample names indicate\n",
    "        replicates of the same condition.\n",
    "    protein_df : pandas.DataFrame\n",
    "        Proteomics dataframe with samples as index and proteins as columns.\n",
    "        Column names should contain protein identifiers matching phospho data.\n",
    "        Values should be log-transformed intensities. Duplicate sample names indicate\n",
    "        replicates of the same condition.\n",
    "    return_non_matched : bool, optional\n",
    "        If True, returns all phosphosites including those without protein matches (unnormalized).\n",
    "        If False (default), returns only successfully normalized phosphosites.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing:\n",
    "        - 'normalized_phospho': DataFrame with protein-normalized phospho data\n",
    "        - 'condition_protein_medians': DataFrame with median protein values per condition\n",
    "        - 'phospho_to_protein_mapping': Dict mapping phosphosites to protein IDs\n",
    "        - 'normalization_success_rate': Float indicating fraction successfully normalized\n",
    "        - 'common_conditions': List of conditions present in both datasets\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Protein IDs are extracted from phosphosite names using '~' or '_' delimiters\n",
    "    - For each condition, calculates median protein abundance across replicates\n",
    "    - Each phosphosite normalized by its parent protein's median in that condition\n",
    "    - By default, only returns phosphosites with successful protein matches\n",
    "    - Set return_non_matched=True to include unmatched phosphosites (unnormalized)\n",
    "    - Preserves biological protein expression differences between conditions\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If no common conditions are found between the two datasets\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> results = normalize_phospho_median(phospho_data, protein_data)\n",
    "    >>> normalized_data = results['normalized_phospho']\n",
    "    >>> success_rate = results['normalization_success_rate']\n",
    "    >>> print(f\"Successfully normalized {success_rate:.1%} of phosphosites\")\n",
    "    \"\"\"\n",
    "    # Find common conditions\n",
    "    phospho_conditions = set(phospho_df.index)\n",
    "    protein_conditions = set(protein_df.index)\n",
    "    common_conditions = phospho_conditions & protein_conditions\n",
    "\n",
    "    if len(common_conditions) == 0:\n",
    "        raise ValueError(\"No common conditions found between phospho and protein data!\")\n",
    "\n",
    "    print(f\"Found {len(common_conditions)} common conditions: {sorted(common_conditions)}\")\n",
    "\n",
    "    # Filter to common conditions\n",
    "    phospho_matched = phospho_df.loc[phospho_df.index.isin(common_conditions)]\n",
    "    protein_matched = protein_df.loc[protein_df.index.isin(common_conditions)]\n",
    "\n",
    "    print(f\"Phospho samples: {len(phospho_matched)}\")\n",
    "    print(f\"Protein samples: {len(protein_matched)}\")\n",
    "\n",
    "    # Extract protein IDs from phosphosite names\n",
    "    def extract_protein_id(phosphosite_name):\n",
    "        \"\"\"Extract protein ID from phosphosite name (format: 'A0A087WUL8~NBPF19_S364_M1')\"\"\"\n",
    "        return (\n",
    "            phosphosite_name.split(\"~\")[0]\n",
    "            if \"~\" in phosphosite_name\n",
    "            else phosphosite_name.split(\"_\")[0]\n",
    "        )\n",
    "\n",
    "    # Create phosphosite to protein mapping\n",
    "    phospho_to_protein = {}\n",
    "    for phosphosite in phospho_matched.columns:\n",
    "        protein_id = extract_protein_id(phosphosite)\n",
    "        phospho_to_protein[phosphosite] = protein_id\n",
    "\n",
    "    print(f\"Mapped {len(phospho_to_protein)} phosphosites to proteins\")\n",
    "\n",
    "    # Calculate condition-level protein medians\n",
    "    # Group protein data by condition and calculate median for each protein\n",
    "    condition_protein_medians = protein_matched.groupby(protein_matched.index).median()\n",
    "\n",
    "    print(f\"Calculated protein medians for {len(condition_protein_medians)} conditions\")\n",
    "    print(f\"Protein medians shape: {condition_protein_medians.shape}\")\n",
    "\n",
    "    # Normalize phospho data\n",
    "    normalized_phospho = phospho_matched.copy()\n",
    "    successfully_normalized_phosphosites = set()\n",
    "    normalization_stats = {\n",
    "        \"total_values\": 0,\n",
    "        \"normalized\": 0,\n",
    "        \"protein_not_found\": 0,\n",
    "        \"missing_protein_values\": 0,\n",
    "    }\n",
    "\n",
    "    for condition in common_conditions:\n",
    "        condition_mask = phospho_matched.index == condition\n",
    "        condition_phospho = phospho_matched.loc[condition_mask]\n",
    "\n",
    "        for phosphosite in phospho_matched.columns:\n",
    "            protein_id = phospho_to_protein[phosphosite]\n",
    "            normalization_stats[\"total_values\"] += sum(condition_mask)\n",
    "\n",
    "            # Find matching protein column\n",
    "            matching_proteins = [\n",
    "                col for col in condition_protein_medians.columns if protein_id in col.split(\";\")\n",
    "            ]\n",
    "\n",
    "            if matching_proteins:\n",
    "                protein_col = matching_proteins[0]\n",
    "                condition_protein_median = condition_protein_medians.loc[condition, protein_col]\n",
    "\n",
    "                if not pd.isna(condition_protein_median):\n",
    "                    # Normalize all replicates of this condition for this phosphosite\n",
    "                    normalized_phospho.loc[condition_mask, phosphosite] = (\n",
    "                        condition_phospho[phosphosite] - condition_protein_median\n",
    "                    )\n",
    "                    normalization_stats[\"normalized\"] += sum(condition_mask)\n",
    "                    successfully_normalized_phosphosites.add(phosphosite)\n",
    "                else:\n",
    "                    normalization_stats[\"missing_protein_values\"] += sum(condition_mask)\n",
    "            else:\n",
    "                normalization_stats[\"protein_not_found\"] += sum(condition_mask)\n",
    "\n",
    "    # Filter to only successfully normalized phosphosites (unless return_non_matched=True)\n",
    "    if not return_non_matched:\n",
    "        print(\"Filtering to only successfully normalized phosphosites...\")\n",
    "        print(f\"Original phosphosites: {len(phospho_matched.columns)}\")\n",
    "        print(f\"Successfully normalized: {len(successfully_normalized_phosphosites)}\")\n",
    "        print(\n",
    "            f\"Removed: {len(phospho_matched.columns) - len(successfully_normalized_phosphosites)}\"\n",
    "        )\n",
    "\n",
    "        normalized_phospho = normalized_phospho[list(successfully_normalized_phosphosites)]\n",
    "\n",
    "        # Also update the original phospho for consistency\n",
    "        phospho_matched = phospho_matched[list(successfully_normalized_phosphosites)]\n",
    "\n",
    "    # Calculate success rate\n",
    "    success_rate = (\n",
    "        normalization_stats[\"normalized\"] / normalization_stats[\"total_values\"]\n",
    "        if normalization_stats[\"total_values\"] > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    print(\"\\nNormalization statistics:\")\n",
    "    print(f\"  Total phosphosite-sample combinations: {normalization_stats['total_values']:,}\")\n",
    "    print(f\"  Successfully normalized: {normalization_stats['normalized']:,} ({success_rate:.1%})\")\n",
    "    print(f\"  Protein not found: {normalization_stats['protein_not_found']:,}\")\n",
    "    print(f\"  Missing protein values: {normalization_stats['missing_protein_values']:,}\")\n",
    "\n",
    "    return {\n",
    "        \"normalized_phospho\": normalized_phospho,\n",
    "        \"condition_protein_medians\": condition_protein_medians,\n",
    "        \"phospho_to_protein_mapping\": phospho_to_protein,\n",
    "        \"normalization_success_rate\": success_rate,\n",
    "        \"common_conditions\": list(common_conditions),\n",
    "        \"original_phospho\": phospho_matched,\n",
    "        \"original_protein\": protein_matched,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_between_asterics(match):\n",
    "    return match.group(1).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_10ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_10ng_Report.tsv', sep = '\\t')\n",
    "ff_20ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_20ng_Report.tsv', sep = '\\t')\n",
    "ff_50ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_50ng_Report.tsv', sep = '\\t')\n",
    "ff_100ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_100ng_Report.tsv', sep = '\\t')\n",
    "ff_200ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_200ng_Report.tsv', sep = '\\t')\n",
    "ff_500ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_500ng_Report.tsv', sep = '\\t')\n",
    "ff_1000ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FF_1000ng_Report.tsv', sep = '\\t')\n",
    "\n",
    "#####\n",
    "\n",
    "ffpe_10ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_10ng_Report.tsv', sep = '\\t')\n",
    "ffpe_20ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_20ng_Report.tsv', sep = '\\t')\n",
    "ffpe_50ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_50ng_Report.tsv', sep = '\\t')\n",
    "ffpe_100ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_100ng_Report.tsv', sep = '\\t')\n",
    "ffpe_200ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_200ng_Report.tsv', sep = '\\t')\n",
    "ffpe_500ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_500ng_Report.tsv', sep = '\\t')\n",
    "ffpe_1000ng = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\nanoPhos_submission\\figure4\\nanoPhos_dilser_FFPE_1000ng_Report.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_1ug = pd.read_csv(r'W:\\User\\Denys\\SN_diffs\\FF_versus_FFPE_report_1000ng.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho = pd.read_csv(r'D:\\Projects\\nanoPhos\\SN_diffs\\nanoPhos_lungAC_Report.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteome = pd.read_csv(r'D:\\Projects\\nanoPhos\\SN_diffs\\DVP_lungAC_Report.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = pd.read_csv(r'C:\\Users\\oliinyk\\Desktop\\mainAnnot.mus_musculus.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_list = [ff_10ng, ff_20ng, ff_50ng, ff_100ng, ff_200ng, ff_500ng, ff_1000ng]\n",
    "ffpe_list = [ffpe_10ng, ffpe_20ng, ffpe_50ng, ffpe_100ng, ffpe_200ng, ffpe_500ng, ffpe_1000ng]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PeptideCollapse on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_list_collapsed = []\n",
    "ffpe_list_collapsed = []\n",
    "for i, l in enumerate(ff_list):\n",
    "    pc = PeptideCollapse()\n",
    "    ff_list_collapsed.append(pc.process_complete_pipeline(l, cutoff=0, fasta_path=r'D:\\Projects\\Spectral libraries\\mouse.fasta'))\n",
    "    pc = PeptideCollapse()\n",
    "    ffpe_list_collapsed.append(pc.process_complete_pipeline(ffpe_list[i], cutoff=0, fasta_path=r'D:\\Projects\\Spectral libraries\\mouse.fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_ffpe_total = [len(ffpe_list_collapsed[0]), len(ffpe_list_collapsed[1]), len(ffpe_list_collapsed[2]), len(ffpe_list_collapsed[3]), len(ffpe_list_collapsed[4]), len(ffpe_list_collapsed[5]), len(ffpe_list_collapsed[6])]\n",
    "nums_ff_total = [len(ff_list_collapsed[0]), len(ff_list_collapsed[1]), len(ff_list_collapsed[2]), len(ff_list_collapsed[3]), len(ff_list_collapsed[4]), len(ff_list_collapsed[5]), len(ff_list_collapsed[6])]\n",
    "ids = [10, 20, 50, 100, 200, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = PhosphoAnalysis()\n",
    "compare_1ug_collapsed = builder.peptideCollapse(compare_1ug, cutoff = 0, fasta_path=r'D:\\Projects\\Spectral libraries\\mouse.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho['R.FileName'] = df_phospho['R.FileName'].replace('20250923_OA4_Evo11_Whisper80_DeOl_lungAC_phosphoDVP_K13_20250924081708', '20250923_OA4_Evo11_Whisper80_DeOl_lungAC_phosphoDVP_K13')\n",
    "builder = PhosphoAnalysis()\n",
    "df_phospho_collapsed = builder.peptideCollapse(df_phospho, cutoff = 0.75,fasta_path = r'D:\\Projects\\Spectral libraries\\human.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = get_cumulative_barplot(ff_list_collapsed, 3, point_size=9, point_color='black')\n",
    "figure.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4a1.pdf', height = 600, width = 600)\n",
    "\n",
    "figure = get_cumulative_barplot(ffpe_list_collapsed, 3, point_size=9, point_color='black')\n",
    "figure.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4a2.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figures 3a & 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_actual, y_predicted):\n",
    "    ss_res = np.sum((y_actual - y_predicted) ** 2)\n",
    "    ss_tot = np.sum((y_actual - np.mean(y_actual)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def linear(x, a, b):\n",
    "    \"\"\"Linear: y = ax + b\"\"\"\n",
    "    return a * x + b\n",
    "\n",
    "def logarithmic(x, a, b):\n",
    "    \"\"\"Logarithmic: y = a*ln(x) + b\"\"\"\n",
    "    return a * np.log(x) + b\n",
    "\n",
    "models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(ids)\n",
    "y = np.array(nums_ffpe_total)\n",
    "\n",
    "popt_lin, pcov_lin = curve_fit(linear, x, y)\n",
    "a_lin, b_lin = popt_lin\n",
    "\n",
    "y_pred_lin = linear(x, a_lin, b_lin)\n",
    "ss_res_lin = np.sum((y - y_pred_lin) ** 2)\n",
    "ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "r2_lin = 1 - (ss_res_lin / ss_tot)\n",
    "\n",
    "x_smooth = np.linspace(min(x), max(x), 200)\n",
    "y_smooth_lin = linear(x_smooth, a_lin, b_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppl. Figure 3b\n",
    "fig1 = go.Figure()\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=x, \n",
    "    y=y,\n",
    "    mode='markers',\n",
    "    name='Data Points',\n",
    "    marker=dict(size=10, color='red'),\n",
    "    hovertemplate='<b>Data Point</b><br>X: %{x}<br>Y: %{y}<extra></extra>'\n",
    "))\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=x_smooth,\n",
    "    y=y_smooth_lin,\n",
    "    mode='lines',\n",
    "    name=f'Linear Fit<br>y = {a_lin:.1f}x + {b_lin:.1f}<br>R² = {r2_lin:.3f}',\n",
    "    line=dict(color='blue', width=3, dash='dash'),\n",
    "    hovertemplate='<b>Linear Curve</b><br>X: %{x:.1f}<br>Y: %{y:.1f}<extra></extra>'\n",
    "))\n",
    "fig1.update_layout(\n",
    "    xaxis_title='X Values',\n",
    "    yaxis_title='Y Values',\n",
    "    hovermode='closest',\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "#fig1.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\suppl_figure3b.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logarithmic fit: y = 7000.658ln(x) + -17794.079\n",
      "R² = 0.9606\n"
     ]
    }
   ],
   "source": [
    "popt_log, pcov_log = curve_fit(logarithmic, ids, nums_ff_total)\n",
    "a, b = popt_log\n",
    "\n",
    "y_pred_log = logarithmic(ids, a, b)\n",
    "ss_res = np.sum(( nums_ff_total - y_pred_log) ** 2)\n",
    "ss_tot = np.sum(( nums_ff_total - np.mean(nums_ff_total)) ** 2)\n",
    "r2_log = 1 - (ss_res / ss_tot)\n",
    "\n",
    "x_smooth = np.linspace(min(ids), max(ids), 200)\n",
    "y_smooth_log = logarithmic(x_smooth, a, b)\n",
    "\n",
    "print(f\"Logarithmic fit: y = {a:.3f}ln(x) + {b:.3f}\")\n",
    "print(f\"R² = {r2_log:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppl. Figure 3a\n",
    "fig1 = go.Figure()\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=ids, \n",
    "    y=nums_ff_total,\n",
    "    mode='markers',\n",
    "    name='Data Points',\n",
    "    marker=dict(size=10, color='red'),\n",
    "    hovertemplate='<b>Data Point</b><br>X: %{x}<br>Y: %{y}<extra></extra>'\n",
    "))\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=x_smooth,\n",
    "    y=y_smooth_log,\n",
    "    mode='lines',\n",
    "    name=f'Logarithmic Fit<br>y = {a:.1f}ln(x) + {b:.1f}<br>R² = {r2_log:.3f}',\n",
    "    line=dict(color='blue', width=3, dash = 'dash'),\n",
    "    hovertemplate='<b>Fitted Curve</b><br>X: %{x:.1f}<br>Y: %{y:.1f}<extra></extra>'\n",
    "))\n",
    "fig1.update_layout(\n",
    "    title='Logarithmic Curve Fit - Interactive Plot',\n",
    "    xaxis_title='X Values',\n",
    "    yaxis_title='Y Values',\n",
    "    hovermode='closest',\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig1.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\suppl_figure3a.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ff = []\n",
    "for df in ff_list_collapsed:\n",
    "    linear_values = np.power(2, df.iloc[:,:3])\n",
    "\n",
    "    n_valid = linear_values.notna().sum(axis=1)\n",
    "    \n",
    "    cv = linear_values.std(axis=1) / linear_values.mean(axis=1)\n",
    "    cv = cv.replace(0, np.nan)\n",
    "\n",
    "    cv[n_valid < 3] = np.nan\n",
    "    \n",
    "    cv_ff.append(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ffpe = []\n",
    "for df in ffpe_list_collapsed:\n",
    "    linear_values = np.power(2, df.iloc[:,:3])\n",
    "\n",
    "    n_valid = linear_values.notna().sum(axis=1)\n",
    "    \n",
    "    cv = linear_values.std(axis=1) / linear_values.mean(axis=1)\n",
    "    cv = cv.replace(0, np.nan)\n",
    "\n",
    "    cv[n_valid < 2] = np.nan\n",
    "    \n",
    "    cv_ffpe.append(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ff_flat = [item for sublist in cv_ff for item in sublist]\n",
    "cv_ffpe_flat = [item for sublist in cv_ffpe for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17118499734001127"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(cv_ffpe_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(cv_ffpe, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = ['#EEA69B', '#E78373', '#E1604C', '#DB452E', '#B3321E', '#8C2718', '#641C11']\n",
    "color_palette_violet = ['#DFCBEC', '#CAA9DF', '#B588D3', '#A066C7', '#8B45BA', '#723899', '#592C78']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, el in enumerate(cv_ff):\n",
    "    fig.add_trace(go.Box(y = el, marker_color = color_palette[i]))\n",
    "    fig.add_trace(go.Box(y = cv_ffpe[i], marker_color = color_palette_violet[i]))\n",
    "fig.update_layout(width = 800, height = 600, template = 'plotly_white')\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4b.pdf', height = 600, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compare_1ug_collapsed_cond = builder.assign_condition_setup()\n",
    "compare_1ug_collapsed_filt = compare_1ug_collapsed_cond.loc[:, (1 - (compare_1ug_collapsed_cond.isna().sum() / len(compare_1ug_collapsed_cond))) >=0.7]\n",
    "compare_1ug_collapsed_imp = ac.imputation_normal_distribution(compare_1ug_collapsed_filt).reset_index()\n",
    "pca_tissue = ac.run_pca(compare_1ug_collapsed_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_title': 'PC1 (0.64)', 'y_title': 'PC2 (0.13)', 'group': 'group'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_tissue[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pca_tissue[0][0], x = 'x', y = 'y', hover_name = 'group',color= 'group', color_discrete_sequence= ['#846db1','#e64126'])\n",
    "fig.update_layout(width = 500, height = 500, template = 'none')\n",
    "fig.update_traces(marker=dict(\n",
    "        size=18,         \n",
    "        opacity=1,               \n",
    "        line=dict(\n",
    "            color='DarkSlateGray',         \n",
    "            width=1                \n",
    "        )\n",
    "    ))\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4d.pdf', height = 500, width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PeptideCollapse()\n",
    "compare_1ug_collapsed = pc.process_complete_pipeline(compare_1ug, cutoff = 0, fasta_path=r'D:\\Projects\\Spectral libraries\\mouse.fasta')\n",
    "compare_1ug_collapsed = compare_1ug_collapsed.dropna()\n",
    "compare_1ug_collapsed['FFPE_mean'] = compare_1ug_collapsed.iloc[:,[0,1,2]].apply(np.mean, axis = 1)\n",
    "compare_1ug_collapsed['FF_mean'] = compare_1ug_collapsed.iloc[:,[3,4,5]].apply(np.mean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_r, pearson_p = stats.pearsonr(\n",
    "    compare_1ug_collapsed['FFPE_mean'], \n",
    "    compare_1ug_collapsed['FF_mean']\n",
    ")\n",
    "\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    compare_1ug_collapsed['FFPE_mean'], \n",
    "    compare_1ug_collapsed['FF_mean']\n",
    ")\n",
    "\n",
    "x_line = np.array([compare_1ug_collapsed['FFPE_mean'].min(), \n",
    "                   compare_1ug_collapsed['FFPE_mean'].max()])\n",
    "y_line = slope * x_line + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.7279, p-value: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "spearman_r, spearman_p = stats.spearmanr(\n",
    "    compare_1ug_collapsed['FFPE_mean'], \n",
    "    compare_1ug_collapsed['FF_mean']\n",
    ")\n",
    "\n",
    "print(f\"Spearman correlation: {spearman_r:.4f}, p-value: {spearman_p:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, pearson_pval = pearsonr(compare_1ug_collapsed['FFPE_mean'], compare_1ug_collapsed['FF_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coef, spearman_pval = spearmanr(compare_1ug_collapsed['FFPE_mean'], compare_1ug_collapsed['FF_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = compare_1ug_collapsed['FFPE_mean'], y = compare_1ug_collapsed['FF_mean'], mode = 'markers', showlegend=False))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_line, \n",
    "    y=y_line, \n",
    "    mode='lines',\n",
    "    line=dict(color='#4A4744', width=3, dash = 'dash'), showlegend=False\n",
    "))\n",
    "fig.update_layout(width = 600, height = 600, template = 'none')\n",
    "fig.update_traces(marker=dict(\n",
    "        size=4,                    \n",
    "        color='grey',         \n",
    "        opacity=0.2,               \n",
    "        line=dict(\n",
    "            color='#0F0E0D',         \n",
    "            width=0.2                \n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4c.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([compare_1ug_collapsed['FFPE_mean'], compare_1ug_collapsed['FF_mean']], group_labels=['FFPE', 'FF'], show_rug=False, bin_size=.1, colors=['#846db1','#e64126'])\n",
    "fig.update_traces(opacity=0.7, selector=dict(type='histogram'))\n",
    "fig.update_layout(width = 600, height = 600, template = 'none')\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4f.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(annotation_dataset, main_dataset, go_term):\n",
    "    data_copy = main_dataset.copy()\n",
    "    annotation_copy = annotation_dataset.copy()\n",
    "\n",
    "    new_col_name = go_term + '_exploded'\n",
    "\n",
    "    annotation_copy['Protein_group'] = annotation_copy['UniProt'].str.split(';')\n",
    "    annotation_copy[new_col_name] = annotation_copy[go_term].str.split(';')\n",
    "\n",
    "    annotation_copy = annotation_copy.explode('Protein_group')\n",
    "    annotation_copy = annotation_copy.explode(new_col_name)\n",
    "\n",
    "    annotation_copy = annotation_copy[['Protein_group', new_col_name]]\n",
    "    fin_df = data_copy.merge(annotation_copy, on='Protein_group', how='left')\n",
    "\n",
    "    return fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gocc = get_annotation(annotation, compare_1ug_collapsed, 'GOCC name')\n",
    "kegg = get_annotation(annotation, compare_1ug_collapsed, 'KEGG name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gocc = gocc[['FFPE_mean', 'FF_mean', 'Protein_group', 'GOCC name_exploded']]\n",
    "kegg = kegg[['FFPE_mean', 'FF_mean', 'Protein_group', 'KEGG name_exploded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting selected valid pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_to_include_kegg = ['Wnt signaling pathway',\n",
    "       'Notch signaling pathway', 'Jak-STAT signaling pathway', 'MAPK signaling pathway', 'mTOR signaling pathway', 'Calcium signaling pathway', 'ErbB signaling pathway', 'Neurotrophin signaling pathway', 'Insulin signaling pathway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_kegg = []\n",
    "spearman_kegg = []\n",
    "for el in pathways_to_include_kegg:\n",
    "    tmp_df = kegg[kegg['KEGG name_exploded'] == el]\n",
    "    pearson_coef, pearson_pval = pearsonr(tmp_df['FFPE_mean'], tmp_df['FF_mean'])\n",
    "    pearson_kegg.append(pearson_coef)\n",
    "\n",
    "    spearman_coef, spearman_pval = spearmanr(tmp_df['FFPE_mean'], tmp_df['FF_mean'])\n",
    "    spearman_kegg.append(spearman_coef)\n",
    "\n",
    "fin_df = pd.DataFrame({'ID': pathways_to_include_kegg, 'Pearson': pearson_kegg, 'Spearman': spearman_kegg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(fin_df, x = 'Spearman', y = 'Pearson', hover_name = 'ID')\n",
    "\n",
    "fig.update_layout(width = 600, height = 600, template = 'none')\n",
    "fig.update_yaxes(range = [0,1])\n",
    "fig.update_xaxes(range = [0,1])\n",
    "fig.update_traces(marker=dict(\n",
    "        size=18,                    \n",
    "        color='#EB420C',         \n",
    "        opacity=1,               \n",
    "        line=dict(\n",
    "            color='DarkSlateGray',         \n",
    "            width=1                \n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=0, y0=0,\n",
    "    x1=1, y1=1,\n",
    "    line=dict(\n",
    "        color='darkgrey',\n",
    "        width=2,\n",
    "        dash='dash'\n",
    "    )\n",
    ")\n",
    "#fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4e.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figure 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = []\n",
    "for idx, el in enumerate(ffpe_list_collapsed):\n",
    "    ratio.append(len(ff_list_collapsed[idx]) / len(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['10ng', '20ng', '50ng', '100ng', '200ng', '500ng', '1000ng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = labels, y = ratio))\n",
    "fig.update_layout(width = 600, height = 600, template = 'plotly_white')\n",
    "fig.update_traces(marker = dict(size = 13, color = '#312353'), line = dict(color = '#846db1'))\n",
    "fig.update_yaxes(range = [0,4.5])\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\suppl_figure3c.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = df_phospho_collapsed.iloc[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "labels = []\n",
    "for el in df_phospho_collapsed.iloc[:,:-6].columns:\n",
    "    nums.append(len(df_phospho_collapsed[el].dropna()))\n",
    "    labels.append(el)\n",
    "d = dict(zip(labels, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.nanmedian(list(d.values())) - stats.iqr(list(d.values()))*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [col for col, count in d.items() if count >= threshold] + list(meta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [col for col, count in d.items() if count <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_collapsed_filtered = df_phospho_collapsed[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching legend file for phospho and proteome analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.read_excel(r'D:\\Random\\lungAC_main_FFPE_tissue_nPhos_forDenys_plate_layout_20250922.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for index, row in legend.iterrows():\n",
    "    if row['sample_type'] == 'tumor (adenocarcinoma)':\n",
    "        tmp.append('AC')\n",
    "    else: tmp.append('H')\n",
    "legend['sample_type'] = tmp\n",
    "legend['sample_ID'] = legend['sample_type'] + '_' + legend['patient'] + '_' + legend['biological_cohort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cols = df_phospho_collapsed_filtered.iloc[:,:-6].columns.tolist()\n",
    "sample_cols_reduced = []\n",
    "for el in sample_cols:\n",
    "    sample_cols_reduced.append(el.split('_')[-1])\n",
    "sample_cols_df = pd.DataFrame({'Full_name':sample_cols, '384_well_position': sample_cols_reduced})\n",
    "\n",
    "sample_cols_df1 = sample_cols_df.merge(legend, on = '384_well_position')\n",
    "sample_cols_df1['sample_ID_reduced'] = sample_cols_df1['sample_type'] + '_' + sample_cols_df1['biological_cohort']\n",
    "condition_df = pd.DataFrame({'Sample':sample_cols_df1['Full_name'], 'Condition':sample_cols_df1['sample_ID_reduced']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a condition setup for phosphoproteome dataset, filtering and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_collapsed1 = builder.assign_condition_setup(condition_df=condition_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_collapsed_filt = df_phospho_collapsed1.loc[:, (1 - (df_phospho_collapsed1.isna().sum() / len(df_phospho_collapsed1))) >=0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_collapsed_imp = ac.imputation_normal_distribution(df_phospho_collapsed_filt).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 6618)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phospho_collapsed_imp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the proteome dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_proteome = df_proteome.rename(columns={'20250923_OA4_Evo11_Whisper80_DeOl_lungAC_phosphoDVP_K13_20250924081708.raw.PG.Quantity': '20250923_OA4_Evo11_Whisper80_DeOl_lungAC_phosphoDVP_K13.raw.PG.Quantity'})\n",
    "sample_cols_prot = df_proteome.iloc[:,1:].columns.tolist()\n",
    "sample_cols_prot_reduced = []\n",
    "for el in sample_cols_prot:\n",
    "    sample_cols_prot_reduced.append(el.split('_')[-1].split('.')[0])\n",
    "sample_cols_prot_df = pd.DataFrame({'Full_name':sample_cols_prot, '384_well_position': sample_cols_prot_reduced})\n",
    "sample_cols_prot_df1 = sample_cols_prot_df.merge(legend, on = '384_well_position')\n",
    "sample_cols_prot_df1['sample_ID_reduced'] = sample_cols_prot_df1['sample_type'] + '_' + sample_cols_prot_df1['biological_cohort']\n",
    "sample_cols_prot_df1 = sample_cols_prot_df1[sample_cols_prot_df1['sample_ID'].isin(sample_cols_df1['sample_ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop blank samples for proteome dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteome1 = df_proteome.drop(['[61] 20250923_OA4_Evo11_Whisper80_DeOl_lungAC_DVP_O16.raw.PG.Quantity','[62] 20250923_OA4_Evo11_Whisper80_DeOl_lungAC_DVP_O18.raw.PG.Quantity','[63] 20250923_OA4_Evo11_Whisper80_DeOl_lungAC_DVP_O20.raw.PG.Quantity'],axis = 1)\n",
    "df_proteome1.columns = ['PG.ProteinGroups'] + sample_cols_prot_df1['sample_ID_reduced'].tolist()\n",
    "df_proteome1 = np.log2(df_proteome1.set_index('PG.ProteinGroups').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of phosphoproteomics dataset based on proteome dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_collapsed_imp1 = df_phospho_collapsed_imp\n",
    "df_phospho_collapsed2 = df_phospho_collapsed_imp1.drop(['sample','subject'], axis = 1).set_index('group')\n",
    "df_phospho_normalized = normalize_phospho_median(df_phospho_collapsed2, df_proteome1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_normalized = df_phospho_normalized['normalized_phospho']\n",
    "df_phospho_normalized = df_phospho_normalized.reset_index()\n",
    "df_phospho_normalized['sample'] = df_phospho_collapsed_imp1['sample']\n",
    "df_phospho_normalized['subject'] = df_phospho_collapsed_imp1['subject']\n",
    "df_phospho_normalized = df_phospho_normalized[df_phospho_normalized['group'] != 'could_be_blank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_normalized1 = df_phospho_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_normalized1['group'] = df_phospho_normalized1['group'].apply(lambda x: x.split('_')[0])\n",
    "df_phospho_normalized1['sample'] = df_phospho_normalized1['sample'].apply(lambda x: x.split('_')[0]) + '_' + df_phospho_normalized1['sample'].apply(lambda x: x.split('_')[-1])\n",
    "df_phospho_normalized1['subject'] = df_phospho_normalized1['subject'].apply(lambda x: x.split('_')[0]) + '_' + df_phospho_normalized1['subject'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = ac.run_pca(df_phospho_normalized1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_title': 'PC1 (0.21)', 'y_title': 'PC2 (0.09)', 'group': 'group'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pca[0][0], x = 'x', y = 'y', labels= \"sample\", color = 'group', color_discrete_sequence= ['#6020B3', '#C4291A'])\n",
    "fig.update_layout(width = 600, height = 600, template = 'none')\n",
    "fig.update_traces(marker=dict(\n",
    "    size=21, \n",
    "    line=dict(width=0.2, color='black')\n",
    "))\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4h.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the condition setup to include all cancer and healthy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho_normalized1['group'] = df_phospho_normalized1['group'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest1 = ac.run_ttest(df_phospho_normalized1, 'AC', 'H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the ID column to distinguish between significant and unsignificant sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for index, row in ttest1.iterrows():\n",
    "    if (row['log2FC'] >= 0.585) & (row['padj'] < 0.05):\n",
    "        tmp.append('upreg')\n",
    "    \n",
    "    elif ((row['log2FC'] <= 0.585) & (row['log2FC'] >= 0)) & (row['padj'] < 0.05):\n",
    "        tmp.append('almost_upreg')\n",
    "    \n",
    "    elif (row['log2FC'] <= -0.585) & (row['padj'] < 0.05):\n",
    "        tmp.append('downreg')\n",
    "\n",
    "    elif ((row['log2FC'] >= -0.585) & (row['log2FC'] <= 0)) & (row['padj'] < 0.05):\n",
    "        tmp.append('almost_downreg')\n",
    "    \n",
    "    else: \n",
    "        tmp.append('noreg')\n",
    "\n",
    "ttest1['ID'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 18)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest1[ttest1['ID'] == 'upreg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest1[ttest1['ID'] == 'downreg'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(ttest1, x = 'log2FC', y = -np.log10(ttest1['padj']), color = 'ID', color_discrete_sequence = ['#BDBDBD','#EE4811','#0B6299','#F7D291', '#77CDE6'])\n",
    "fig.update_traces(marker=dict(\n",
    "    size=10, \n",
    "    line=dict(width=0.5, color='black')\n",
    "))\n",
    "fig.add_vline(x = -0.585, line_dash = 'dash', line_color = 'black')\n",
    "fig.add_vline(x = 0.585, line_dash = 'dash', line_color = 'black')\n",
    "fig.add_hline(y = 1.3, line_dash = 'dash', line_color = 'black')\n",
    "fig.update_xaxes(title = \"log2FC (AC vs H)\")\n",
    "fig.update_yaxes(title = '-log10(p-adjusted)')\n",
    "fig.update_layout(width = 600, height = 600, template = 'plotly_white', showlegend = False)\n",
    "fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4i.png', height = 600, width = 600, scale = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting significantly up- and down-regulated sites for EnrichR analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ttest1[ttest1['ID'] == 'upreg']\n",
    "a['Gene'] = a['identifier'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[0])\n",
    "a['Gene'].to_excel(r'D:\\ttest_upreg_gene.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ttest1[ttest1['ID'] == 'downreg']\n",
    "a['Gene'] = a['identifier'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[0])\n",
    "a['Gene'].to_excel(r'D:\\ttest_downreg_gene.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ttest1\n",
    "a['Gene'] = a['identifier'].apply(lambda x: x.split('~')[1]).apply(lambda x: x.split('_')[0])\n",
    "a['Gene'].to_excel(r'D:\\ttest_background.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4J "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 entries were omitted due to even length (no central position).\n",
      "24 entries were omitted due to invalid central phosphoacceptor.\n",
      "Use the 'omited_entries' attribute to view dropped enteries due to invalid sequences.\n",
      "\n",
      "Calculating percentiles for upregulated sites (1964 substrates)\n",
      "Scoring 1898 ser_thr substrates\n",
      "Calculating percentile for 1898 ser_thr substrates\n",
      "100%|██████████| 311/311 [00:02<00:00, 150.02it/s] \n",
      "                                                  \n",
      "\n",
      "Calculating percentiles for downregulated sites (1229 substrates)\n",
      "Scoring 1185 ser_thr substrates\n",
      "Calculating percentile for 1185 ser_thr substrates\n",
      "100%|██████████| 311/311 [00:02<00:00, 153.76it/s] \n",
      "                                                  \n",
      "\n",
      "Calculating percentiles for background (unregulated) sites (4436 substrates)\n",
      "Scoring 4282 ser_thr substrates\n",
      "Calculating percentile for 4282 ser_thr substrates\n",
      "100%|██████████| 311/311 [00:02<00:00, 137.51it/s] \n",
      "                                                  \n"
     ]
    }
   ],
   "source": [
    "kin_df = df_phospho_collapsed[['PTM_Collapse_key', 'kinase_sequence']]\n",
    "kinase_df, kinase_class = run_kinase_prediction(df_phospho_normalized1, kin_df, 'AC', 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for index, row in kinase_df.iterrows():\n",
    "    if ((-np.log10(row['most_sig_fisher_adj_pval'])>=1.3) & (row['most_sig_log2_freq_factor']>=0)):\n",
    "        tmp.append('upreg')\n",
    "    elif ((-np.log10(row['most_sig_fisher_adj_pval'])>=1.3) & (row['most_sig_log2_freq_factor']<=0)):\n",
    "        tmp.append('downreg')\n",
    "    else:\n",
    "        tmp.append('noreg')\n",
    "\n",
    "kinase_df['ID'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot kinase prediction volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(kinase_df, y = -np.log10(kinase_df['most_sig_fisher_adj_pval']), x = 'most_sig_log2_freq_factor', color = 'ID', color_discrete_sequence=['#BDBDBD','#EE4811','#0B6299'])\n",
    "fig.update_traces(marker=dict(\n",
    "    size=10, \n",
    "    line=dict(width=0.5, color='black')\n",
    "))\n",
    "fig.add_hline(y = 1.3, line_dash = 'dash', line_color = 'black')\n",
    "fig.update_xaxes(title = \"log2(FF)\")\n",
    "fig.update_yaxes(title = '-log10(p-adjusted)')\n",
    "fig.update_layout(width = 800, height = 400, template = 'none', showlegend = False)\n",
    "#fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4j.pdf', height = 400, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 4k and 4l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing EnrichR results for up- and down-regulated sites from volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_upreg = pd.read_csv(r'D:\\wiki_up.txt', sep = '\\t')\n",
    "gocc_upreg = pd.read_csv(r'D:\\gobp_up.txt', sep = '\\t')\n",
    "kegg_downreg = pd.read_csv(r'D:\\bioplanet_down.txt', sep = '\\t')\n",
    "gobp_downreg = pd.read_csv(r'D:\\reactome_down.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_upreg = wiki_upreg[wiki_upreg['Adjusted P-value']<=0.05]\n",
    "gocc_upreg = gocc_upreg[gocc_upreg['Adjusted P-value']<=0.05]\n",
    "kegg_downreg = kegg_downreg[kegg_downreg['Adjusted P-value']<=0.05]\n",
    "gobp_downreg = gobp_downreg[gobp_downreg['Adjusted P-value']<=0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_upreg['Odds Ratio'] = np.log2(wiki_upreg['Odds Ratio'])\n",
    "gocc_upreg['Odds Ratio'] = np.log2(gocc_upreg['Odds Ratio'])\n",
    "kegg_downreg['Odds Ratio'] = np.log2(kegg_downreg['Odds Ratio'])\n",
    "gobp_downreg['Odds Ratio'] = np.log2(gobp_downreg['Odds Ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching names of selected significantly enriched pathways for up- and down-regulated sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_include_upreg = ['Aerobic Glycolysis WP4629','EGF EGFR Signaling WP437', 'Lipid Metabolism Pathway WP3965', 'ATM Signaling In Development And Disease WP3878','Target Of Rapamycin Signaling WP1471','Focal Adhesion WP306','MAPK Signaling WP382']\n",
    "to_include_downreg = ['Apoptotic Execution Phase', 'Signaling by Rho GTPases', 'Membrane Trafficking', 'Tight junction', 'Spliceosome']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting upregulated pathways (Figure 4k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_upreg = wiki_upreg[wiki_upreg['Term'].isin(to_include_upreg)].sort_values('Odds Ratio', ascending=True)\n",
    "fig = px.bar(wiki_upreg, y = 'Term', x = 'Odds Ratio', color = 'Adjusted P-value', color_continuous_scale=[\n",
    "                 [0, '#5a4a6f'], \n",
    "                 [0.25, '#9970ab'], \n",
    "                 [0.5, '#c994c7'],    \n",
    "                 [0.75, '#d4b9da'],  \n",
    "                 [1, '#e0d0e8']       \n",
    "             ])\n",
    "fig.update_layout(width = 600, height = 600, template = 'none')\n",
    "#fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4k.pdf', height = 600, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting downregulated pathways (Figure 4l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gobp_downreg = gobp_downreg[gobp_downreg['Term'].isin(to_include_downreg)].sort_values('Odds Ratio', ascending=True)\n",
    "kegg_downreg = kegg_downreg[kegg_downreg['Term'].isin(to_include_downreg)].sort_values('Odds Ratio', ascending=True)\n",
    "downreg = pd.concat([gobp_downreg, kegg_downreg], axis = 0).sort_values('Odds Ratio', ascending=True)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "fig = px.bar(downreg, y = 'Term', x = 'Odds Ratio', color = 'Adjusted P-value', color_continuous_scale=[\n",
    "                 [0, '#5a4a6f'],   \n",
    "                [0.25, '#9970ab'], \n",
    "                 [0.5, '#c994c7'], \n",
    "                 [0.75, '#d4b9da'],  \n",
    "                 [1, '#e0d0e8']       \n",
    "             ])\n",
    "fig.update_layout(width = 700, height = 400, template = 'none')\n",
    "#fig.write_image(r'D:\\Projects\\nanoPhos\\figures_upd\\figure4\\figure4l.pdf', height = 600, width = 600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoPhos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
